//lmk any input about the approach on any item, we could do this a few different ways tbh

0. text sorter (overall main function)
- detects and ignores whitespace
- detects and ignores comments
- detects symbols (and sends them to the lexeme list but im still working on that)
- detects when something might be a keyword or variable and calls for a dictionary check (also working on the dictionary)
- detects when input too large
- produces error messages

1. source file
- seems easy enough, we just print out the input file we used right? am i overthinking this or underthinking it?

2. lexeme list
- lexeme list implemented using dynamically allocated 2d array (or maybe just a wasteful massive preset array based on max size idk if he cares)
- use text sorter to send symbols and their token directly to the lexeme list
- use trie dictionary to look for keywords
- if buffer string not found in dicitonary, store in lexeme list and categorize it as identsym (decimal value 2). (maybe ill add vars to the trie idk)

3. token list
- doesnt seem bad either just gotta build it from the lexeme list
- list the tokens from the lexeme list, along with any variable names categrized by identsym
