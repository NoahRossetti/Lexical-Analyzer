//lmk any input about the approach on any item, we could do this a few different ways tbh

0. text sorter (overall main function)
- detects and ignores whitespace
- detects and ignores comments
- detects symbols (and sends them to the lexeme list but im still working on that)
- detects when something might be a keyword or variable and calls for a dictionary check (requires copying string into a buffer array) (also working on the dictionary)
- detects when input too large
- produces error messages

1. source file
- seems easy enough, we just print out the input file we used right? am i overthinking this or underthinking it?

2. lexeme list
- lexeme list implemented using dynamically allocated 2d array (or maybe just a wasteful massive preset array based on max size idk if he cares)
- use text sorter to send symbols and their token directly to the lexeme list
- use trie dictionary to look for keywords
- if buffer string not found in dicitonary, store in lexeme list and categorize it as identsym (decimal value 2). (maybe ill add vars to the trie idk)

Update on lexeme list:
//dynamically allocated 2d array to store lexemes
//there is a max char count in one dimension, but we have no clue how long the input could be
//also the lexeme arrary needs to have 2 lists technically, but ill just make it so that the array alternates in the list
//as in even addresses are the lexemes and the odd addresses are the tokens or something to that effect
// then a seperate function to print out the lexeme list
// which will also double up as the token list generator

3. token list
- doesnt seem bad either just gotta build it from the lexeme list
- list the tokens from the lexeme list, along with any variable names categorized under identsym

4. documentation

5. comments and formatting
